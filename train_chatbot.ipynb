{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hi', 'there'], 'greeting'), (['Hey'], 'greeting'), (['Hola'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'qA_greeting'), (['Knock-Knock'], 'qA_greeting'), (['Hi', ',', 'How', 'is', 'it', 'going', '?'], 'qB_greeting'), (['How', 'are', 'you', 'doing', '?'], 'qB_greeting'), (['Hi', ',', 'Nice', 'to', 'meet', 'you'], 'qC_greeting'), (['It', 'is', 'a', 'pleasure', 'to', 'meet', 'you', '.'], 'qC_greeting'), (['Good', 'Morning'], 'qC_greeting'), (['Good', 'Afternoon'], 'qC_greeting'), (['Good', 'Evening'], 'qC_greeting'), (['Good', 'Night'], 'qC_greeting'), (['What', \"'s\", 'up', '?'], 'qD_greeting'), (['What', 'is', 'up', '?'], 'qD_greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Nice', 'chatting', 'to', 'you', ',', 'bye'], 'goodbye'), (['Till', 'next', 'time'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Awesome', ',', 'thanks'], 'thanks'), (['Thanks', 'for', 'helping', 'me'], 'thanks'), (['You', 'are', 'arrogant'], 'arrogant'), (['your', 'arrogance'], 'arrogant'), (['You', 'are', 'jealous'], 'you_jealous'), (['You', 'should', 'be', 'ashamed'], 'ashamed'), (['Do', 'you', 'have', 'feelings', '?'], 'feelings'), (['What', 'is', 'your', 'fear', '?'], 'fear'), (['What', 'is', 'your', 'mood', '?'], 'mood'), (['What', 'makes', 'you', 'sad', '?'], 'what_sad'), (['What', 'makes', 'you', 'mad'], 'what_mad'), (['What', 'do', 'you', 'worry'], 'what_worry'), (['How', 'can', 'I', 'offend', 'you'], 'offend'), (['do', 'not', 'lie'], 'lie'), (['Do', 'you', 'feel', 'emotions'], 'emotions'), (['Tell', 'me', 'about', 'relationships'], 'relationships'), (['Tell', 'me', 'about', 'your', 'dreams'], 'dreams'), (['Are', 'you', 'jealous'], 'are_jealous'), (['Are', 'you', 'sad'], 'are_sad'), (['What', 'are', 'your', 'interests'], 'interests'), (['What', 'do', 'you', 'like', 'to', 'do', '?'], 'interests'), (['What', 'is', 'your', 'name'], 'name'), (['What', 'can', 'you', 'eat'], 'eat'), (['Why', 'ca', \"n't\", 'you', 'eat', 'food'], 'why_eat'), (['If', 'you', 'could', 'eat', 'food', ',', 'what', 'would', 'you', 'eat', '?'], 'what_eat'), (['What', 'is', 'your', 'location'], 'location'), (['Where', 'are', 'you', '?'], 'location'), (['Do', 'you', 'have', 'any', 'brothers', '?'], 'sibblings'), (['Do', 'you', 'have', 'any', 'sibblings', '?'], 'sibblings'), (['Who', 'is', 'your', 'father'], 'father'), (['Who', 'created', 'you'], 'father'), (['Who', 'is', 'your', 'boss'], 'boss'), (['under', 'whose', 'command', ',', 'do', 'you', 'work', '?'], 'boss'), (['What', 'is', 'your', 'age'], 'age'), (['do', 'you', 'drink'], 'drink'), (['can', 'a', 'robot', 'get', 'drunk', '?'], 'drunk'), (['when', 'do', 'you', 'get', 'drunk', '?'], 'drunk'), (['is', 'it', 'possible', 'that', 'you', 'get', 'drunk'], 'drunk'), (['Tell', 'me', 'a', 'joke'], 'joke'), (['can', 'you', 'be', 'funny'], 'joke'), (['tell', 'me', 'something', 'funny'], 'joke'), (['Who', 'are', 'you', '?'], 'who'), (['Are', 'you', 'stupid'], 'stupid'), (['Will', 'you', 'die', '?'], 'die'), (['I', 'hope', 'that', 'you', 'die'], 'die'), (['I', 'do', 'not', 'want', 'to', 'die'], 'i_die'), (['Can', 'you', 'breathe'], 'breathe'), (['Can', 'you', 'move'], 'move'), (['can', 'you', 'go'], 'move'), (['What', 'kind', 'of', 'computer'], 'computer'), (['What', 'kind', 'of', 'hardware'], 'computer'), (['What', 'operating', 'systems'], 'os'), (['What', 'is', 'it', 'like', 'being', 'a', 'computer'], 'being_computer'), (['What', 'is', 'your', 'favorite', 'programming', 'language'], 'language'), (['What', 'is', 'a', 'chat', 'bot'], 'chatbot'), (['What', 'is', 'a', 'chat', 'robot', '?'], 'chatbot')]\n",
      "['Hi', 'there', 'Hey', 'Hola', 'Hello', 'Good', 'day', 'Is', 'anyone', 'there', '?', 'Knock-Knock', 'Hi', ',', 'How', 'is', 'it', 'going', '?', 'How', 'are', 'you', 'doing', '?', 'Hi', ',', 'Nice', 'to', 'meet', 'you', 'It', 'is', 'a', 'pleasure', 'to', 'meet', 'you', '.', 'Good', 'Morning', 'Good', 'Afternoon', 'Good', 'Evening', 'Good', 'Night', 'What', \"'s\", 'up', '?', 'What', 'is', 'up', '?', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Nice', 'chatting', 'to', 'you', ',', 'bye', 'Till', 'next', 'time', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'Awesome', ',', 'thanks', 'Thanks', 'for', 'helping', 'me', 'You', 'are', 'arrogant', 'your', 'arrogance', 'You', 'are', 'jealous', 'You', 'should', 'be', 'ashamed', 'Do', 'you', 'have', 'feelings', '?', 'What', 'is', 'your', 'fear', '?', 'What', 'is', 'your', 'mood', '?', 'What', 'makes', 'you', 'sad', '?', 'What', 'makes', 'you', 'mad', 'What', 'do', 'you', 'worry', 'How', 'can', 'I', 'offend', 'you', 'do', 'not', 'lie', 'Do', 'you', 'feel', 'emotions', 'Tell', 'me', 'about', 'relationships', 'Tell', 'me', 'about', 'your', 'dreams', 'Are', 'you', 'jealous', 'Are', 'you', 'sad', 'What', 'are', 'your', 'interests', 'What', 'do', 'you', 'like', 'to', 'do', '?', 'What', 'is', 'your', 'name', 'What', 'can', 'you', 'eat', 'Why', 'ca', \"n't\", 'you', 'eat', 'food', 'If', 'you', 'could', 'eat', 'food', ',', 'what', 'would', 'you', 'eat', '?', 'What', 'is', 'your', 'location', 'Where', 'are', 'you', '?', 'Do', 'you', 'have', 'any', 'brothers', '?', 'Do', 'you', 'have', 'any', 'sibblings', '?', 'Who', 'is', 'your', 'father', 'Who', 'created', 'you', 'Who', 'is', 'your', 'boss', 'under', 'whose', 'command', ',', 'do', 'you', 'work', '?', 'What', 'is', 'your', 'age', 'do', 'you', 'drink', 'can', 'a', 'robot', 'get', 'drunk', '?', 'when', 'do', 'you', 'get', 'drunk', '?', 'is', 'it', 'possible', 'that', 'you', 'get', 'drunk', 'Tell', 'me', 'a', 'joke', 'can', 'you', 'be', 'funny', 'tell', 'me', 'something', 'funny', 'Who', 'are', 'you', '?', 'Are', 'you', 'stupid', 'Will', 'you', 'die', '?', 'I', 'hope', 'that', 'you', 'die', 'I', 'do', 'not', 'want', 'to', 'die', 'Can', 'you', 'breathe', 'Can', 'you', 'move', 'can', 'you', 'go', 'What', 'kind', 'of', 'computer', 'What', 'kind', 'of', 'hardware', 'What', 'operating', 'systems', 'What', 'is', 'it', 'like', 'being', 'a', 'computer', 'What', 'is', 'your', 'favorite', 'programming', 'language', 'What', 'is', 'a', 'chat', 'bot', 'What', 'is', 'a', 'chat', 'robot', '?']\n",
      "81 documents\n",
      "47 classes ['age', 'are_jealous', 'are_sad', 'arrogant', 'ashamed', 'being_computer', 'boss', 'breathe', 'chatbot', 'computer', 'die', 'dreams', 'drink', 'drunk', 'eat', 'emotions', 'father', 'fear', 'feelings', 'goodbye', 'greeting', 'i_die', 'interests', 'joke', 'language', 'lie', 'location', 'mood', 'move', 'name', 'offend', 'os', 'qA_greeting', 'qB_greeting', 'qC_greeting', 'qD_greeting', 'relationships', 'sibblings', 'stupid', 'thanks', 'what_eat', 'what_mad', 'what_sad', 'what_worry', 'who', 'why_eat', 'you_jealous']\n",
      "127 unique lemmatized words [\"'s\", ',', '.', 'a', 'about', 'afternoon', 'age', 'any', 'anyone', 'are', 'arrogance', 'arrogant', 'ashamed', 'awesome', 'be', 'being', 'bos', 'bot', 'breathe', 'brother', 'bye', 'ca', 'can', 'chat', 'chatting', 'command', 'computer', 'could', 'created', 'day', 'die', 'do', 'doing', 'dream', 'drink', 'drunk', 'eat', 'emotion', 'evening', 'father', 'favorite', 'fear', 'feel', 'feeling', 'food', 'for', 'funny', 'get', 'go', 'going', 'good', 'goodbye', 'hardware', 'have', 'hello', 'helpful', 'helping', 'hey', 'hi', 'hola', 'hope', 'how', 'i', 'if', 'interest', 'is', 'it', 'jealous', 'joke', 'kind', 'knock-knock', 'language', 'later', 'lie', 'like', 'location', 'mad', 'make', 'me', 'meet', 'mood', 'morning', 'move', \"n't\", 'name', 'next', 'nice', 'night', 'not', 'of', 'offend', 'operating', 'pleasure', 'possible', 'programming', 'relationship', 'robot', 'sad', 'see', 'should', 'sibblings', 'something', 'stupid', 'system', 'tell', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'under', 'up', 'want', 'what', 'when', 'where', 'who', 'whose', 'why', 'will', 'work', 'worry', 'would', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import random\n",
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "            \n",
    "print(documents)\n",
    "print (words)\n",
    "# lemmatize, lower each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n",
      "[[list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      " [list([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      " ...\n",
      " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
      " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      " [list([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]]\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "        # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "        output_row = list(output_empty)\n",
    "        output_row[classes.index(doc[1])] = 1\n",
    "        training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "10287/10287 [==============================] - 2s 227us/step - loss: 3.3751 - accuracy: 0.1580TA: 1s - loss: 3.6162  - ETA: 0s - loss: 3.4993 - accuracy - ETA: 0s - loss: 3.4448 - accura\n",
      "Epoch 2/400\n",
      "10287/10287 [==============================] - 2s 223us/step - loss: 2.0695 - accuracy: 0.4614\n",
      "Epoch 3/400\n",
      "10287/10287 [==============================] - 2s 224us/step - loss: 1.1520 - accuracy: 0.6881TA: 0s - loss: 1.2 - ETA: 0s - loss: 1.2151 \n",
      "Epoch 4/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.7537 - accuracy: 0.7934\n",
      "Epoch 5/400\n",
      "10287/10287 [==============================] - 2s 208us/step - loss: 0.5255 - accuracy: 0.8559\n",
      "Epoch 6/400\n",
      "10287/10287 [==============================] - 2s 216us/step - loss: 0.4275 - accuracy: 0.8807\n",
      "Epoch 7/400\n",
      "10287/10287 [==============================] - 2s 208us/step - loss: 0.3375 - accuracy: 0.9085\n",
      "Epoch 8/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.2902 - accuracy: 0.92001s - loss: - ETA: 0s - loss: 0.3050 - accura - ETA: 0s - loss:\n",
      "Epoch 9/400\n",
      "10287/10287 [==============================] - 2s 209us/step - loss: 0.2483 - accuracy: 0.93190s - loss: 0.2522 - accu\n",
      "Epoch 10/400\n",
      "10287/10287 [==============================] - 2s 212us/step - loss: 0.2224 - accuracy: 0.9376\n",
      "Epoch 11/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.1965 - accuracy: 0.94231s - - ETA: 0s - loss: 0.1951 - accuracy - ETA: 0s - loss: 0.1969 - accura - ETA: 0s - loss: 0.1967 - accu\n",
      "Epoch 12/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.1825 - accuracy: 0.94652s - loss: 0.1879 - accuracy: 0.95 - ETA: 2s - l - ETA: 1s - loss: 0 - ETA: 0s - loss:\n",
      "Epoch 13/400\n",
      "10287/10287 [==============================] - 2s 217us/step - loss: 0.1766 - accuracy: 0.9469\n",
      "Epoch 14/400\n",
      "10287/10287 [==============================] - 2s 214us/step - loss: 0.1585 - accuracy: 0.95221s - - E\n",
      "Epoch 15/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.95 - 2s 210us/step - loss: 0.1434 - accuracy: 0.9561\n",
      "Epoch 16/400\n",
      "10287/10287 [==============================] - 2s 209us/step - loss: 0.1339 - accuracy: 0.9567\n",
      "Epoch 17/400\n",
      "10287/10287 [==============================] - 2s 212us/step - loss: 0.1329 - accuracy: 0.9607\n",
      "Epoch 18/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.1257 - accuracy: 0.95922s - - ETA: 0s - loss: 0.1257 - accuracy: \n",
      "Epoch 19/400\n",
      "10287/10287 [==============================] - 2s 213us/step - loss: 0.1231 - accuracy: 0.95880s - loss: 0.1228 \n",
      "Epoch 20/400\n",
      "10287/10287 [==============================] - 2s 209us/step - loss: 0.1155 - accuracy: 0.9625\n",
      "Epoch 21/400\n",
      "10287/10287 [==============================] - 2s 213us/step - loss: 0.1151 - accuracy: 0.96030s\n",
      "Epoch 22/400\n",
      "10287/10287 [==============================] - 2s 212us/step - loss: 0.1078 - accuracy: 0.9643\n",
      "Epoch 23/400\n",
      "10287/10287 [==============================] - 2s 231us/step - loss: 0.1023 - accuracy: 0.96580s - loss: 0.1005 - accuracy\n",
      "Epoch 24/400\n",
      "10287/10287 [==============================] - 2s 207us/step - loss: 0.1029 - accuracy: 0.96411s - - ETA: 1s - loss: 0.0979 - accuracy - ETA: 0s - l\n",
      "Epoch 25/400\n",
      "10287/10287 [==============================] - 2s 208us/step - loss: 0.1010 - accuracy: 0.9641\n",
      "Epoch 26/400\n",
      "10287/10287 [==============================] - 2s 225us/step - loss: 0.0990 - accuracy: 0.9677\n",
      "Epoch 27/400\n",
      "10287/10287 [==============================] - 2s 192us/step - loss: 0.0970 - accuracy: 0.9663: 0s - loss: 0.0991 - \n",
      "Epoch 28/400\n",
      "10287/10287 [==============================] - 2s 192us/step - loss: 0.0929 - accuracy: 0.9682\n",
      "Epoch 29/400\n",
      "10287/10287 [==============================] - 2s 192us/step - loss: 0.0907 - accuracy: 0.9663TA: 0s - loss: 0.094\n",
      "Epoch 30/400\n",
      "10287/10287 [==============================] - 2s 193us/step - loss: 0.0896 - accuracy: 0.9693\n",
      "Epoch 31/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - 2s 191us/step - loss: 0.0866 - accuracy: 0.9685\n",
      "Epoch 32/400\n",
      "10287/10287 [==============================] - 2s 190us/step - loss: 0.0846 - accuracy: 0.96910s - loss: 0\n",
      "Epoch 33/400\n",
      "10287/10287 [==============================] - 2s 189us/step - loss: 0.0842 - accuracy: 0.96841s - loss: 0.0791 -  - E\n",
      "Epoch 34/400\n",
      "10287/10287 [==============================] - 2s 188us/step - loss: 0.0802 - accuracy: 0.96970s - loss: 0.0800 - accuracy: 0.96\n",
      "Epoch 35/400\n",
      "10287/10287 [==============================] - 2s 189us/step - loss: 0.0781 - accuracy: 0.97080s - loss: 0.0793 - accuracy - ETA: 0s - l\n",
      "Epoch 36/400\n",
      "10287/10287 [==============================] - 2s 189us/step - loss: 0.0782 - accuracy: 0.9712: 0s - loss: 0.0760 - accura - ETA: 0s - loss: 0.0775 - accuracy: \n",
      "Epoch 37/400\n",
      "10287/10287 [==============================] - 2s 207us/step - loss: 0.0782 - accuracy: 0.9693\n",
      "Epoch 38/400\n",
      "10287/10287 [==============================] - 2s 218us/step - loss: 0.0766 - accuracy: 0.9711\n",
      "Epoch 39/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0756 - accuracy: 0.97171s - loss: 0.0730 - accuracy - ETA: 1s - ETA: 0s - loss: 0.0791 -  - ETA: 0s - loss: 0.0757 - ac\n",
      "Epoch 40/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0769 - accuracy: 0.97252s - l - ETA: 1s - loss: - ETA: 0s - loss: 0.0762 - accuracy - ETA: 0s - loss: 0.0765 - \n",
      "Epoch 41/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0699 - accuracy: 0.97361s - loss: 0.0660 - accuracy - ETA: 0s - loss: 0.0679 -  - ETA: 0s - loss: 0.0\n",
      "Epoch 42/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0713 - accuracy: 0.9721\n",
      "Epoch 43/400\n",
      "10287/10287 [==============================] - 2s 211us/step - loss: 0.0768 - accuracy: 0.9693: \n",
      "Epoch 44/400\n",
      "10287/10287 [==============================] - 2s 229us/step - loss: 0.0746 - accuracy: 0.97080s - loss: 0.075\n",
      "Epoch 45/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0709 - accuracy: 0.9731\n",
      "Epoch 46/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0661 - accuracy: 0.97400s - loss: 0.0665 - accuracy: 0.\n",
      "Epoch 47/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0645 - accuracy: 0.97322s - loss: 0.0525 - accura - ETA: 1s - los\n",
      "Epoch 48/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0673 - accuracy: 0.97260s - loss: 0.0680 -  - ETA: 0s - loss: 0.0672 - accuracy: \n",
      "Epoch 49/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0653 - accuracy: 0.9740\n",
      "Epoch 50/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0705 - accuracy: 0.97390s - loss: 0.0719 - accu\n",
      "Epoch 51/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0673 - accuracy: 0.9727\n",
      "Epoch 52/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0649 - accuracy: 0.9740\n",
      "Epoch 53/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0644 - accuracy: 0.9747\n",
      "Epoch 54/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0688 - accuracy: 0.9739\n",
      "Epoch 55/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0624 - accuracy: 0.97461s - loss: 0.0633 - accura - - ETA: 0s - loss: 0.0622 - accuracy: \n",
      "Epoch 56/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0662 - accuracy: 0.9729\n",
      "Epoch 57/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0627 - accuracy: 0.9744\n",
      "Epoch 58/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0648 - accuracy: 0.97510s -\n",
      "Epoch 59/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0644 - accuracy: 0.97351s - loss: 0.0589 - accura - ETA: 1s - loss: 0.0605 - accu\n",
      "Epoch 60/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0663 - accuracy: 0.97450s - loss: 0.0663 - accuracy: 0.97\n",
      "Epoch 61/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0620 - accuracy: 0.9754\n",
      "Epoch 62/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0596 - accuracy: 0.97600s - loss: 0.0596 - accuracy: \n",
      "Epoch 63/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0608 - accuracy: 0.9751\n",
      "Epoch 64/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0590 - accuracy: 0.9756\n",
      "Epoch 65/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0620 - accuracy: 0.97362s - loss: 0.0696 -  - ETA: 0s - loss: 0.0650 \n",
      "Epoch 66/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0617 - accuracy: 0.97601s - loss: 0.0673  - ETA: 0s - loss: 0\n",
      "Epoch 67/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0597 - accuracy: 0.9749 ETA: 0s - ETA: 0s - loss: 0.0606 - accuracy: 0.\n",
      "Epoch 68/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0581 - accuracy: 0.9768\n",
      "Epoch 69/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0570 - accuracy: 0.97581s - loss: - ETA: 0s - loss: 0.0574 -  - ETA: 0s - loss: 0.0581 - accuracy - ETA: 0s - loss: 0.0569 - ac\n",
      "Epoch 70/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0545 - accuracy: 0.9792\n",
      "Epoch 71/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9765 ETA: 1s - loss: 0.0632  - ETA: 0s - 2s 195us/step - loss: 0.0562 - accuracy: 0.9769\n",
      "Epoch 72/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0548 - accuracy: 0.9773\n",
      "Epoch 73/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0600 - accuracy: 0.97380s - loss: 0.0600 - accuracy: 0.\n",
      "Epoch 74/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0539 - accuracy: 0.97671s -\n",
      "Epoch 75/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0521 - accuracy: 0.9788\n",
      "Epoch 76/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9770 ETA: 1s - loss: - ETA: 0s - loss: 0 - 2s 195us/step - loss: 0.0551 - accuracy: 0.9768\n",
      "Epoch 77/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0561 - accuracy: 0.97671s - loss: 0.0490  - ETA: 1s - loss: - ETA: 0s - loss: 0.0536 -  - ETA: 0s - loss: 0.0561 - accuracy: \n",
      "Epoch 78/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0579 - accuracy: 0.97601s - loss: 0.0638 - accura - ETA: 1s - loss: 0.0574  - ETA: 1s - ETA: 0s - loss: 0.0607 - accu\n",
      "Epoch 79/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0558 - accuracy: 0.97731s - ETA: 0s - los\n",
      "Epoch 80/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0549 - accuracy: 0.97511s - loss: 0.0554 - accuracy - ETA: 1s - loss: -\n",
      "Epoch 81/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0503 - accuracy: 0.9778\n",
      "Epoch 82/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0533 - accuracy: 0.9782\n",
      "Epoch 83/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0533 - accuracy: 0.97800s - ETA: 0s - loss: 0.0537 - accuracy: 0.\n",
      "Epoch 84/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0546 - accuracy: 0.9772\n",
      "Epoch 85/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0555 - accuracy: 0.97810s -\n",
      "Epoch 86/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0480 - accuracy: 0.97850s - loss: 0.0488 - accuracy: \n",
      "Epoch 87/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0512 - accuracy: 0.9783\n",
      "Epoch 88/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0511 - accuracy: 0.97911s - loss: 0 - ETA: 0s - los\n",
      "Epoch 89/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0514 - accuracy: 0.97852s - ETA: 1s - loss: 0.0491 - accuracy - ETA: 0s - loss: 0.0492 - accura - ETA: 0s - los\n",
      "Epoch 90/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0513 - accuracy: 0.97711s - loss: 0.0440 - accuracy: 0. - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0506 - accuracy\n",
      "Epoch 91/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0559 - accuracy: 0.9748\n",
      "Epoch 92/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0487 - accuracy: 0.9792\n",
      "Epoch 93/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0517 - accuracy: 0.97730s - loss: 0.0508 - accuracy: \n",
      "Epoch 94/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0508 - accuracy: 0.97660s - loss: 0.0511 - accuracy: 0.\n",
      "Epoch 95/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0505 - accuracy: 0.9777\n",
      "Epoch 96/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0502 - accuracy: 0.9778TA: 0s - loss: 0 - ETA: 0s - loss: 0.0494 - \n",
      "Epoch 97/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0485 - accuracy: 0.97910s - loss: 0.0498 -  - ETA: 0s - loss: 0.0483 - accu\n",
      "Epoch 98/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0498 - accuracy: 0.9780\n",
      "Epoch 99/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0481 - accuracy: 0.9778\n",
      "Epoch 100/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0462 - accuracy: 0.98030s - loss: 0.0474 -  - ETA: 0s - loss: 0.0472 - accuracy\n",
      "Epoch 101/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9752 ETA: 1s - ETA:  - 2s 201us/step - loss: 0.0546 - accuracy: 0.9754\n",
      "Epoch 102/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0465 - accuracy: 0.9808 - ETA: 0s - loss: 0\n",
      "Epoch 103/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0485 - accuracy: 0.9788\n",
      "Epoch 104/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0476 - accuracy: 0.9790\n",
      "Epoch 105/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0521 - accuracy: 0.9767\n",
      "Epoch 106/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0447 - accuracy: 0.9793 - ETA: 1s - loss: 0.0456 - accura - ETA: 0s -\n",
      "Epoch 107/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0497 - accuracy: 0.9791\n",
      "Epoch 108/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0445 - accuracy: 0.98141s - loss: 0.0443 - accuracy - ETA: 1s - loss: - ETA: 0s - loss: 0.0434 - accuracy - ETA: 0s - loss: 0.0436 - accuracy\n",
      "Epoch 109/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0485 - accuracy: 0.97940s - loss: 0.0484 - accura\n",
      "Epoch 110/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0458 - accuracy: 0.97920s - loss: 0.0458 - accuracy: \n",
      "Epoch 111/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0495 - accuracy: 0.9776\n",
      "Epoch 112/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0466 - accuracy: 0.9772\n",
      "Epoch 113/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0512 - accuracy: 0.9784: 0s -\n",
      "Epoch 114/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0456 - accuracy: 0.9791\n",
      "Epoch 115/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0453 - accuracy: 0.9796\n",
      "Epoch 116/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9778 ETA: 1s - loss: 0.0 - 2s 201us/step - loss: 0.0472 - accuracy: 0.9778\n",
      "Epoch 117/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0465 - accuracy: 0.97802s - loss: - ETA: 0s - loss: 0.0466 - accu\n",
      "Epoch 118/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0459 - accuracy: 0.9799\n",
      "Epoch 119/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0465 - accuracy: 0.9805\n",
      "Epoch 120/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0454 - accuracy: 0.9805\n",
      "Epoch 121/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0439 - accuracy: 0.98130s - loss: 0.0436 - ac\n",
      "Epoch 122/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0499 - accuracy: 0.97770s - loss: 0.0521 - accuracy - ETA: 0s - l\n",
      "Epoch 123/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0451 - accuracy: 0.9792\n",
      "Epoch 124/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0466 - accuracy: 0.97890s - loss: 0.0468 - accuracy: 0.97\n",
      "Epoch 125/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9809 ETA: 0s - loss: 0 - 2s 197us/step - loss: 0.0437 - accuracy: 0.9808\n",
      "Epoch 126/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0449 - accuracy: 0.9795\n",
      "Epoch 127/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0455 - accuracy: 0.97982s - loss: 0.0423 - accuracy: 0.98 - ETA: 1s -\n",
      "Epoch 128/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0460 - accuracy: 0.9784\n",
      "Epoch 129/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0435 - accuracy: 0.97991s - loss: - ETA: 0s - loss: 0.0439 - accuracy - ETA: 0s - loss: 0\n",
      "Epoch 130/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0448 - accuracy: 0.9799\n",
      "Epoch 131/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9818 ETA: 2s - loss: 0.0411 -  - ETA: 1s - los - ETA: 0s - loss: 0.0476 -  - ETA: 0s - loss: 0.0447  - 2s 195us/step - loss: 0.0430 - accuracy: 0.9819\n",
      "Epoch 132/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0466 - accuracy: 0.9778\n",
      "Epoch 133/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0456 - accuracy: 0.97901s - loss:\n",
      "Epoch 134/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0441 - accuracy: 0.97990s - loss: 0.0439 - accura\n",
      "Epoch 135/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0428 - accuracy: 0.98150s - loss: 0.0429 - accuracy\n",
      "Epoch 136/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0431 - accuracy: 0.97940s - loss: 0\n",
      "Epoch 137/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0489 - accuracy: 0.9783\n",
      "Epoch 138/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0436 - accuracy: 0.9804TA - ETA\n",
      "Epoch 139/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0429 - accuracy: 0.98000s - loss: 0.0445 - accuracy - ETA: 0s - loss: 0.044\n",
      "Epoch 140/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0464 - accuracy: 0.97890s - loss: 0.0459 - accuracy - ETA: 0s - loss: 0.0467 - accuracy: 0.\n",
      "Epoch 141/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0450 - accuracy: 0.97861s - loss: 0.0444 - accura - ETA: 0s -\n",
      "Epoch 142/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0442 - accuracy: 0.97800s - loss: 0.0442 \n",
      "Epoch 143/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0432 - accuracy: 0.9793\n",
      "Epoch 144/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0429 - accuracy: 0.98070s - loss: 0.0411  - ETA: 0s - loss: 0.0419 - accuracy - ETA: 0s - loss: 0.0423 - accuracy: \n",
      "Epoch 145/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0430 - accuracy: 0.97900s - loss: 0.0442 - accuracy\n",
      "Epoch 146/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.97 - 2s 195us/step - loss: 0.0403 - accuracy: 0.9795\n",
      "Epoch 147/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0393 - accuracy: 0.98170s -\n",
      "Epoch 148/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0393 - accuracy: 0.98200s - loss: 0.0405 - accuracy - ETA: 0s - loss: 0.0397 - accuracy: 0.98\n",
      "Epoch 149/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0424 - accuracy: 0.97802s\n",
      "Epoch 150/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0396 - accuracy: 0.9811\n",
      "Epoch 151/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0428 - accuracy: 0.98020s - loss: 0.0429 - accuracy: \n",
      "Epoch 152/400\n",
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0409 - accuracy: 0.98041s -\n",
      "Epoch 153/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0452 - accuracy: 0.9790: 0s - loss: 0.0448 - accuracy: 0.97\n",
      "Epoch 154/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0426 - accuracy: 0.9796\n",
      "Epoch 155/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0403 - accuracy: 0.97990s - loss: 0.0402 - accura\n",
      "Epoch 156/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0403 - accuracy: 0.9809\n",
      "Epoch 157/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0403 - accuracy: 0.98081s - l\n",
      "Epoch 158/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0390 - accuracy: 0.98130s - loss: 0.0403 - accura\n",
      "Epoch 159/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0419 - accuracy: 0.9794\n",
      "Epoch 160/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0447 - accuracy: 0.97791s - l\n",
      "Epoch 161/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0436 - accuracy: 0.97990s - loss: 0.0440 - ac\n",
      "Epoch 162/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.978800 - ETA: 2s - loss: 0.0 - ETA: 1s - loss: 0.0380 - accuracy - 2s 195us/step - loss: 0.0441 - accuracy: 0.9789\n",
      "Epoch 163/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0429 - accuracy: 0.9809\n",
      "Epoch 164/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0420 - accuracy: 0.9806\n",
      "Epoch 165/400\n",
      "10287/10287 [==============================] - 2s 207us/step - loss: 0.0402 - accuracy: 0.97991s - loss: 0.0396 -  - ETA: 0s - loss: - ETA: 0s - loss: 0.0398 - accuracy: 0.\n",
      "Epoch 166/400\n",
      "10287/10287 [==============================] - 2s 208us/step - loss: 0.0411 - accuracy: 0.98081s - loss: -\n",
      "Epoch 167/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0407 - accuracy: 0.98090s - loss: 0.0405 - accuracy: 0.98\n",
      "Epoch 168/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0386 - accuracy: 0.98140s - loss: 0.0379 - accuracy: 0.\n",
      "Epoch 169/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0392 - accuracy: 0.98192s - loss: 0.0409 - accuracy: 0.98 - ETA: 1s - loss: 0.0383 - accuracy - ETA: 1s - loss:\n",
      "Epoch 170/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0433 - accuracy: 0.98041s - loss: 0.0592 - accuracy - ETA: 1s - ETA: 0s - loss:\n",
      "Epoch 171/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0443 - accuracy: 0.97891s - loss: 0.0448 - accuracy - ETA: 0s - ETA: 0s - loss: 0.0444 - accuracy: 0.97\n",
      "Epoch 172/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0377 - accuracy: 0.9807\n",
      "Epoch 173/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0442 - accuracy: 0.9795\n",
      "Epoch 174/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0407 - accuracy: 0.9816\n",
      "Epoch 175/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0385 - accuracy: 0.9833TA: 2s -\n",
      "Epoch 176/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0414 - accuracy: 0.97931s - loss: 0.0432 -  - ETA: 1s - loss: 0.0414 - accuracy: 0.98 - ETA: 1s - ETA: 0s - loss: 0.0416 - \n",
      "Epoch 177/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0421 - accuracy: 0.9788\n",
      "Epoch 178/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0398 - accuracy: 0.9808TA: 2s -\n",
      "Epoch 179/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0382 - accuracy: 0.98241s - loss: 0.0320 -  - ETA: 1s - loss: 0.0372  - ETA\n",
      "Epoch 180/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0387 - accuracy: 0.9818\n",
      "Epoch 181/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0383 - accuracy: 0.98090s - loss: 0.0383 - accuracy - ETA: 0s - loss: 0.0393 - accuracy: 0.98 - ETA: 0s - loss: 0.0394 - accuracy - ETA: 0s - loss: 0.0386 - accuracy:  - ETA: 0s - loss: 0.0378 - accuracy: 0.\n",
      "Epoch 182/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9813 ETA: 0s - 2s 196us/step - loss: 0.0401 - accuracy: 0.9811\n",
      "Epoch 183/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0394 - accuracy: 0.98152s\n",
      "Epoch 184/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0405 - accuracy: 0.9821TA: 1s - loss: 0 - ETA: 1s - loss: 0.0361 -  - ETA: 0s - loss: - ETA: 0s - loss: 0.0405 - accuracy - ETA: 0s - loss: 0.0410 - accuracy: 0.98\n",
      "Epoch 185/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9815 ETA: 0s - loss: 0 - 2s 195us/step - loss: 0.0378 - accuracy: 0.9814\n",
      "Epoch 186/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9771 ETA: 1s - loss: 0.0416 -  - 2s 196us/step - loss: 0.0430 - accuracy: 0.9773\n",
      "Epoch 187/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0391 - accuracy: 0.98120s - loss: 0.0394 - accuracy: \n",
      "Epoch 188/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0382 - accuracy: 0.9825\n",
      "Epoch 189/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0405 - accuracy: 0.98230s - loss: - ETA: 0s - loss: 0.0409 - accura\n",
      "Epoch 190/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0373 - accuracy: 0.9816\n",
      "Epoch 191/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0365 - accuracy: 0.9818\n",
      "Epoch 192/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0416 - accuracy: 0.98081s - loss: 0.0426 -  - ETA: 0s - l\n",
      "Epoch 193/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0388 - accuracy: 0.98291s - l\n",
      "Epoch 194/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0397 - accuracy: 0.98141s - loss: - ETA: 0s - loss: 0.0397  - ETA: 0s - loss: 0.0390 - accuracy: \n",
      "Epoch 195/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0408 - accuracy: 0.98061s -\n",
      "Epoch 196/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0379 - accuracy: 0.98240s - loss: 0.0\n",
      "Epoch 197/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0406 - accuracy: 0.98020s - l\n",
      "Epoch 198/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9805 ETA: 1s - loss: 0.0433 - accuracy - ETA: 0s - 2s 196us/step - loss: 0.0409 - accuracy: 0.9806\n",
      "Epoch 199/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0370 - accuracy: 0.98180s - loss: 0.0368 - accuracy - ETA: 0s - loss: 0.0364 - accuracy: 0.98\n",
      "Epoch 200/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0360 - accuracy: 0.98211s - loss: 0.0352  - ETA: 1s - loss: 0.0332 - accuracy - ETA: 1s - loss: 0.0350  - ETA: 0s - loss: 0.0359 - accuracy - ETA: 0s - loss: 0.036\n",
      "Epoch 201/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0390 - accuracy: 0.9802\n",
      "Epoch 202/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0377 - accuracy: 0.98151s - loss: 0\n",
      "Epoch 203/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0355 - accuracy: 0.98260s - loss: 0.0338 - accu\n",
      "Epoch 204/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0422 - accuracy: 0.97872s - l - ETA: 1s - loss: - ETA: 0s - loss: 0.0405 -  - ETA: 0s - loss: 0.0419 - accuracy\n",
      "Epoch 205/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0373 - accuracy: 0.98091s - loss: - ETA\n",
      "Epoch 206/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0366 - accuracy: 0.9805\n",
      "Epoch 207/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0364 - accuracy: 0.9814\n",
      "Epoch 208/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0376 - accuracy: 0.98041s - los - ETA: 0s - loss: 0.0\n",
      "Epoch 209/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.98 - 2s 196us/step - loss: 0.0402 - accuracy: 0.9804\n",
      "Epoch 210/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0366 - accuracy: 0.9818\n",
      "Epoch 211/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0384 - accuracy: 0.98080s - loss: 0.0384 - accuracy: 0.98\n",
      "Epoch 212/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0398 - accuracy: 0.98130s -\n",
      "Epoch 213/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0411 - accuracy: 0.97942s - loss: 0.0362  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.0420 - accura - ETA: 0s - loss:\n",
      "Epoch 214/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0380 - accuracy: 0.9823\n",
      "Epoch 215/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.98 - 2s 196us/step - loss: 0.0391 - accuracy: 0.9814\n",
      "Epoch 216/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0389 - accuracy: 0.98000s - loss: 0.0384 -  - ETA: 0s - loss:\n",
      "Epoch 217/400\n",
      "10287/10287 [==============================] - 2s 207us/step - loss: 0.0400 - accuracy: 0.98181s - loss: 0.0397 - accuracy - ETA: 1s - loss: 0\n",
      "Epoch 218/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0403 - accuracy: 0.97940s - loss:\n",
      "Epoch 219/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0384 - accuracy: 0.9817: 1s -\n",
      "Epoch 220/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0369 - accuracy: 0.98081s - loss: 0.0348 - ac\n",
      "Epoch 221/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0383 - accuracy: 0.98220s - loss:\n",
      "Epoch 222/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0351 - accuracy: 0.9826\n",
      "Epoch 223/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0392 - accuracy: 0.98021s - loss: 0.0391 - accuracy - E\n",
      "Epoch 224/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0354 - accuracy: 0.98330s - loss: 0.0361 - ac\n",
      "Epoch 225/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.98 - 2s 201us/step - loss: 0.0335 - accuracy: 0.9831\n",
      "Epoch 226/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0368 - accuracy: 0.98150s - ETA: 0s - loss: 0.0370 - accuracy: 0.\n",
      "Epoch 227/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0361 - accuracy: 0.9814\n",
      "Epoch 228/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0400 - accuracy: 0.9801\n",
      "Epoch 229/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0357 - accuracy: 0.9830\n",
      "Epoch 230/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0395 - accuracy: 0.98250s - loss: 0.0385 - accu\n",
      "Epoch 231/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0374 - accuracy: 0.98191s - loss: 0.0352  - ETA: 0s - loss: 0.0349 - accuracy - ETA: 0s - los\n",
      "Epoch 232/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0393 - accuracy: 0.97981s - loss: 0.0378 -  - ETA: 1s - ETA: 0s - loss: 0.0392 - accura\n",
      "Epoch 233/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0365 - accuracy: 0.98180s - loss: 0.0368 - accura\n",
      "Epoch 234/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0375 - accuracy: 0.9813\n",
      "Epoch 235/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0387 - accuracy: 0.9812\n",
      "Epoch 236/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0381 - accuracy: 0.98231s - loss: 0.0406 -  - ETA: 1s - loss: - ETA: 0s - loss: 0.0379  - ETA: 0s - loss: 0.0380 - accuracy: 0.\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0350 - accuracy: 0.98351s - loss: 0.0403 - accuracy:  - ETA: 1s - loss: 0.0383 - accuracy - ETA: 0s\n",
      "Epoch 238/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0362 - accuracy: 0.9816\n",
      "Epoch 239/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9827 ETA: 2s - loss: 0.0196 - accuracy: 0.99 - ETA:  - ETA: 1s - loss: - ETA: 0s - loss: 0.0358 - ac - 2s 196us/step - loss: 0.0352 - accuracy: 0.9826\n",
      "Epoch 240/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0383 - accuracy: 0.9811\n",
      "Epoch 241/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0354 - accuracy: 0.9820: 1s - loss: 0.0355 - ac - ETA: 0s - loss: 0.0367 - \n",
      "Epoch 242/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9813 ETA: 2s - 2s 196us/step - loss: 0.0368 - accuracy: 0.9812\n",
      "Epoch 243/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0358 - accuracy: 0.98200s - loss: 0.0357 - accuracy: \n",
      "Epoch 244/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0387 - accuracy: 0.98110s -\n",
      "Epoch 245/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0366 - accuracy: 0.98241s - loss: - ETA: 0s - los\n",
      "Epoch 246/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0334 - accuracy: 0.98290s - loss: 0.0325 \n",
      "Epoch 247/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0363 - accuracy: 0.98200s - loss: 0.0369 - accuracy - ETA: 0s - loss: 0.0367 - accuracy\n",
      "Epoch 248/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0350 - accuracy: 0.9809TA: 1s\n",
      "Epoch 249/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0346 - accuracy: 0.98350s - loss: 0.0354 - accuracy: \n",
      "Epoch 250/400\n",
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0370 - accuracy: 0.9815TA: 2s - loss: 0.0274 - ac - ETA: 0s - loss: 0.037\n",
      "Epoch 251/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0377 - accuracy: 0.9819\n",
      "Epoch 252/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0332 - accuracy: 0.98451s - loss: 0.0326 -  - ETA: 1s - loss: 0.0307 - accuracy - ETA: 1s - loss: - ETA: 0s - loss: 0.0314 - \n",
      "Epoch 253/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0356 - accuracy: 0.9827\n",
      "Epoch 254/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0395 - accuracy: 0.97950s - loss: 0.0390 - \n",
      "Epoch 255/400\n",
      "10287/10287 [==============================] - 2s 200us/step - loss: 0.0376 - accuracy: 0.9815TA: 2s - loss: 0.0312 -  - - ETA: 0s - loss: 0.036\n",
      "Epoch 256/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0342 - accuracy: 0.9825\n",
      "Epoch 257/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0345 - accuracy: 0.9827\n",
      "Epoch 258/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0365 - accuracy: 0.98030s - loss: 0.0362 - accuracy: 0.98\n",
      "Epoch 259/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9808 ETA: 1s - loss: 0.0373 - accuracy - E - 2s 196us/step - loss: 0.0378 - accuracy: 0.9808\n",
      "Epoch 260/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9807 ETA: 0s - loss: 0.0372 - accura - ETA: 0s - loss: 0.0384 - accuracy - ETA: 0s - loss: 0.0377 - accuracy - 2s 195us/step - loss: 0.0387 - accuracy: 0.9806\n",
      "Epoch 261/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0347 - accuracy: 0.9816TA: 1s -\n",
      "Epoch 262/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0352 - accuracy: 0.98141s - loss: 0.0378 - accuracy - ETA: 0s\n",
      "Epoch 263/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.98 - 2s 196us/step - loss: 0.0362 - accuracy: 0.9822\n",
      "Epoch 264/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0359 - accuracy: 0.9826\n",
      "Epoch 265/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0357 - accuracy: 0.9812TA: 1s - loss: 0.0555 -  - ETA: 0s - loss: 0.0354 - \n",
      "Epoch 266/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0393 - accuracy: 0.9787\n",
      "Epoch 267/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0349 - accuracy: 0.98150s - l\n",
      "Epoch 268/400\n",
      "10287/10287 [==============================] - 2s 194us/step - loss: 0.0351 - accuracy: 0.9829\n",
      "Epoch 269/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0322 - accuracy: 0.98331s - loss: 0.0360 \n",
      "Epoch 270/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0357 - accuracy: 0.98240s - loss: 0.036\n",
      "Epoch 271/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0379 - accuracy: 0.9802\n",
      "Epoch 272/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0367 - accuracy: 0.98141s - ETA: 0s - loss: 0.0\n",
      "Epoch 273/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0379 - accuracy: 0.9808\n",
      "Epoch 274/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9817 ETA: 0s - 2s 195us/step - loss: 0.0371 - accuracy: 0.9814\n",
      "Epoch 275/400\n",
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0360 - accuracy: 0.98181s - loss: 0.0391 -  - ETA: 1s - loss: 0.0343 - accuracy - ETA: 1s - loss: 0.0350  - ETA: 0s\n",
      "Epoch 276/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9804 ETA: 1s - loss: 0.0398  - ETA:  - 2s 195us/step - loss: 0.0373 - accuracy: 0.9804\n",
      "Epoch 277/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0369 - accuracy: 0.9812\n",
      "Epoch 278/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0349 - accuracy: 0.9832TA: 1s - loss: 0 - ETA: 1s - loss: 0.0399  - ETA: \n",
      "Epoch 279/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0358 - accuracy: 0.98071s - loss:\n",
      "Epoch 280/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0346 - accuracy: 0.9832\n",
      "Epoch 281/400\n",
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0366 - accuracy: 0.9821\n",
      "Epoch 282/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0383 - accuracy: 0.98251s - l\n",
      "Epoch 283/400\n",
      "10287/10287 [==============================] - 2s 209us/step - loss: 0.0375 - accuracy: 0.97970s\n",
      "Epoch 284/400\n",
      "10287/10287 [==============================] - 2s 213us/step - loss: 0.0358 - accuracy: 0.98052s - loss: 0.0457 - accuracy: 0.96 - E - ETA: 1s - loss: 0.0372 - accuracy - ETA: \n",
      "Epoch 285/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.0345 - accuracy: 0.9844\n",
      "Epoch 286/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.0360 - accuracy: 0.9819TA: 2s - loss: - ETA: 1s - loss: 0.0309 - accuracy - ETA: 1s - loss: 0.0311 -  - ETA: 0s - l\n",
      "Epoch 287/400\n",
      "10287/10287 [==============================] - 2s 213us/step - loss: 0.0376 - accuracy: 0.98230s - loss: 0.0380 - accuracy: \n",
      "Epoch 288/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9823 ETA: 1s - loss: 0 - ETA: 1s - loss: 0.0352  - ETA: 0s - loss: 0 - 2s 206us/step - loss: 0.0341 - accuracy: 0.9822\n",
      "Epoch 289/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0360 - accuracy: 0.98290s - loss: 0.0334  - ETA: 0s - loss: 0.0336 - accuracy - ETA: 0s - loss: 0.0355 - accu\n",
      "Epoch 290/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0366 - accuracy: 0.98250s - loss: 0.0369 - \n",
      "Epoch 291/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0367 - accuracy: 0.98090s - loss: 0\n",
      "Epoch 292/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0356 - accuracy: 0.98210s - loss: 0.0354 - accuracy: \n",
      "Epoch 293/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0345 - accuracy: 0.98181s - loss: 0.0387  - E\n",
      "Epoch 294/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9834 ETA: 1s - ETA: 0s - loss: 0.0339 - accuracy - 2s 201us/step - loss: 0.0329 - accuracy: 0.9836\n",
      "Epoch 295/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0362 - accuracy: 0.98230s - loss: 0.0365 - accuracy - ETA: 0s - loss: 0\n",
      "Epoch 296/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0362 - accuracy: 0.98132s - loss: 0 - ETA: 1s - loss: - ETA: 0s - los\n",
      "Epoch 297/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0340 - accuracy: 0.9830\n",
      "Epoch 298/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0330 - accuracy: 0.98181s - loss: - ETA: 0s - loss: 0.0308 - accuracy - ETA: 0s - l\n",
      "Epoch 299/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0357 - accuracy: 0.9816\n",
      "Epoch 300/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0389 - accuracy: 0.9818: 0s - loss: 0.0377 -  - ETA: 0s - loss: 0.0391 - accura\n",
      "Epoch 301/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0368 - accuracy: 0.98230s - loss: 0\n",
      "Epoch 302/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0339 - accuracy: 0.98190s - loss: 0.0334 - accuracy: 0.98 - ETA: 0s - loss: 0.0336 - accuracy\n",
      "Epoch 303/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0317 - accuracy: 0.9830\n",
      "Epoch 304/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0330 - accuracy: 0.98202s - loss: 0.0436 - accuracy: 0.97 - ETA: 1s -\n",
      "Epoch 305/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0376 - accuracy: 0.9803\n",
      "Epoch 306/400\n",
      "10287/10287 [==============================] - 2s 200us/step - loss: 0.0378 - accuracy: 0.98040s -\n",
      "Epoch 307/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0327 - accuracy: 0.9839TA: 2s - loss: 0.0382 - accuracy:  - ETA: 0s - los\n",
      "Epoch 308/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0339 - accuracy: 0.98211s - loss: 0.0376 - accuracy - ETA: 1s - ETA: 0s - loss:\n",
      "Epoch 309/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9815 ETA: 1s - loss: - ETA: 0s - loss: 0.0357 -  - ETA: 0s - loss: 0.0345 - accuracy: 0.98 - 2s 201us/step - loss: 0.0345 - accuracy: 0.9816\n",
      "Epoch 310/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0341 - accuracy: 0.98191s - ETA: 0s -\n",
      "Epoch 311/400\n",
      "10287/10287 [==============================] - 2s 200us/step - loss: 0.0351 - accuracy: 0.9831\n",
      "Epoch 312/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0339 - accuracy: 0.9840\n",
      "Epoch 313/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0336 - accuracy: 0.98241s - loss: - ETA: 0s - loss: 0.035\n",
      "Epoch 314/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0353 - accuracy: 0.98261s - loss: 0.0364 - accuracy - ETA: 1s - ETA: 0s - loss: 0.0349 -  - ETA: 0s - loss: 0.0355 - accuracy\n",
      "Epoch 315/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0325 - accuracy: 0.9830\n",
      "Epoch 316/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0330 - accuracy: 0.98330s - loss: 0.0340 - \n",
      "Epoch 317/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0373 - accuracy: 0.9804\n",
      "Epoch 318/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0326 - accuracy: 0.9827\n",
      "Epoch 319/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0350 - accuracy: 0.98111s - loss: - ETA: 0s - loss: - ETA: 0s - loss: 0.0355 - accuracy: 0.98\n",
      "Epoch 320/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0332 - accuracy: 0.98141s - loss: 0.0279 - accura - ETA: 1s - - ETA: 0s - loss: 0.031\n",
      "Epoch 321/400\n",
      "10287/10287 [==============================] - 2s 212us/step - loss: 0.0345 - accuracy: 0.9832\n",
      "Epoch 322/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0339 - accuracy: 0.9842\n",
      "Epoch 323/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0333 - accuracy: 0.98350s - loss: 0.0328 - accuracy: \n",
      "Epoch 324/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.98 - 2s 204us/step - loss: 0.0329 - accuracy: 0.9831\n",
      "Epoch 325/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0352 - accuracy: 0.98130s\n",
      "Epoch 326/400\n",
      "10287/10287 [==============================] - 2s 214us/step - loss: 0.0322 - accuracy: 0.9826\n",
      "Epoch 327/400\n",
      "10287/10287 [==============================] - 2s 214us/step - loss: 0.0344 - accuracy: 0.98360s - loss: 0.0\n",
      "Epoch 328/400\n",
      "10287/10287 [==============================] - 2s 214us/step - loss: 0.0328 - accuracy: 0.98290s - loss: 0.0336  - ETA: 0s - loss: 0.0\n",
      "Epoch 329/400\n",
      "10287/10287 [==============================] - 2s 213us/step - loss: 0.0320 - accuracy: 0.98311s - loss: 0.0396 - accuracy - ETA: 1s - - ETA: 0s - ETA: 0s - loss: 0.0312 - accuracy: \n",
      "Epoch 330/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0371 - accuracy: 0.98000s - loss: 0.0373 - accuracy: 0.\n",
      "Epoch 331/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0354 - accuracy: 0.9819TA: \n",
      "Epoch 332/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0331 - accuracy: 0.98310s - loss: 0.0334  - ETA: 0s - loss: 0.0339 - accuracy - ETA: 0s - loss: 0.0338 - accura\n",
      "Epoch 333/400\n",
      "10287/10287 [==============================] - 2s 211us/step - loss: 0.0375 - accuracy: 0.98100s - loss: 0.0381 - accuracy\n",
      "Epoch 334/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0362 - accuracy: 0.98201s - loss: 0 - ETA: 0s - loss:\n",
      "Epoch 335/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0341 - accuracy: 0.98140s - los\n",
      "Epoch 336/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0326 - accuracy: 0.98191s - loss: 0.0331  - ETA: 0s - loss: 0.0352 -  - ETA: 0s - loss: 0\n",
      "Epoch 337/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0316 - accuracy: 0.9851\n",
      "Epoch 338/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0341 - accuracy: 0.9822\n",
      "Epoch 339/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0330 - accuracy: 0.9831TA: 0s\n",
      "Epoch 340/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0348 - accuracy: 0.98130s\n",
      "Epoch 341/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0333 - accuracy: 0.98260s - loss: 0\n",
      "Epoch 342/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0334 - accuracy: 0.98290s - loss: 0.0333 \n",
      "Epoch 343/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0318 - accuracy: 0.9820\n",
      "Epoch 344/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0377 - accuracy: 0.98151s - ETA: 0s - loss: 0.0379 - accuracy\n",
      "Epoch 345/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0361 - accuracy: 0.9826\n",
      "Epoch 346/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0335 - accuracy: 0.9824\n",
      "Epoch 347/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0352 - accuracy: 0.98171s - ETA: 0s - loss: 0.0320  - ETA: 0s - loss: 0.0338 \n",
      "Epoch 348/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0367 - accuracy: 0.9795\n",
      "Epoch 349/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0352 - accuracy: 0.98091s - loss: 0.0369 - accuracy - ETA: 1s - loss: 0.0358  - ETA\n",
      "Epoch 350/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0353 - accuracy: 0.9812\n",
      "Epoch 351/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0324 - accuracy: 0.98201s - loss: 0.0330 - accura - ETA: 1s - loss: - ETA: 0s - loss: 0.0338 - accuracy - ETA: 0s - loss:\n",
      "Epoch 352/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0332 - accuracy: 0.98240s - loss: 0.0350 -  - ETA: 0s - loss: 0.0339 - ac\n",
      "Epoch 353/400\n",
      "10287/10287 [==============================] - 2s 195us/step - loss: 0.0375 - accuracy: 0.9806\n",
      "Epoch 354/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0362 - accuracy: 0.98191s - loss: 0 - ETA: 0s - loss: 0.037\n",
      "Epoch 355/400\n",
      "10287/10287 [==============================] - 2s 196us/step - loss: 0.0345 - accuracy: 0.9822\n",
      "Epoch 356/400\n",
      "10287/10287 [==============================] - 2s 197us/step - loss: 0.0348 - accuracy: 0.9834\n",
      "Epoch 357/400\n",
      "10287/10287 [==============================] - 2s 198us/step - loss: 0.0342 - accuracy: 0.98220s - loss: 0.0352 - \n",
      "Epoch 358/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0339 - accuracy: 0.98300s - l\n",
      "Epoch 359/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9840 ETA: 0s - loss: 0.0323 - ac - 2s 204us/step - loss: 0.0330 - accuracy: 0.9839\n",
      "Epoch 360/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0312 - accuracy: 0.98320s - loss: - ETA: 0s - loss: 0.0320 - accura\n",
      "Epoch 361/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0364 - accuracy: 0.98021s - loss: 0.0288 - accuracy - ETA: 1s - loss: 0.0369  - ETA: 0s - loss: 0.0366 - accuracy: 0.\n",
      "Epoch 362/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0322 - accuracy: 0.98110s - l\n",
      "Epoch 363/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0319 - accuracy: 0.98401s - loss: 0.0320 - accura - ETA: 1s - loss: 0.0300 - accuracy - ETA: 1s - loss: 0.0313  - ETA: 0s - loss: 0.0339 - accuracy - ETA: 0s - loss: 0.0329 - accuracy - ETA: 0s - loss: 0.0335 \n",
      "Epoch 364/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0331 - accuracy: 0.98351s - loss: 0.0334 - accuracy - ETA\n",
      "Epoch 365/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9830 ETA: 0s - los - 2s 201us/step - loss: 0.0344 - accuracy: 0.9828\n",
      "Epoch 366/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0308 - accuracy: 0.9834\n",
      "Epoch 367/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0364 - accuracy: 0.9820\n",
      "Epoch 368/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0331 - accuracy: 0.9823\n",
      "Epoch 369/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0322 - accuracy: 0.9834\n",
      "Epoch 370/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0309 - accuracy: 0.98261s - loss: 0.0322  - ETA: 0s - loss: 0\n",
      "Epoch 371/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0319 - accuracy: 0.98150s - loss: 0.0320 - accuracy: 0.\n",
      "Epoch 372/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0331 - accuracy: 0.98351s - los\n",
      "Epoch 373/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0300 - accuracy: 0.98431s - loss: 0.0307 - accuracy - ETA: 1s - ETA: 0s - loss: 0.0301 - accuracy\n",
      "Epoch 374/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0317 - accuracy: 0.98351s - loss:\n",
      "Epoch 375/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0303 - accuracy: 0.98421s - ETA: 0s - loss:\n",
      "Epoch 376/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0325 - accuracy: 0.9832\n",
      "Epoch 377/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0379 - accuracy: 0.9827\n",
      "Epoch 378/400\n",
      "10287/10287 [==============================] - 2s 207us/step - loss: 0.0332 - accuracy: 0.98311s - ETA: 0s - loss: 0.0328  - ETA: 0s - loss: 0.0337 - accuracy - ETA: 0s - loss: 0.0331 - accuracy: \n",
      "Epoch 379/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0316 - accuracy: 0.98240s\n",
      "Epoch 380/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0301 - accuracy: 0.98330s - loss: 0.0\n",
      "Epoch 381/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0342 - accuracy: 0.98220s - loss: 0.0348 - accuracy\n",
      "Epoch 382/400\n",
      "10287/10287 [==============================] - 2s 222us/step - loss: 0.0335 - accuracy: 0.98140s - loss: 0.0313 - ac\n",
      "Epoch 383/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0317 - accuracy: 0.9833: 0s - loss: 0.0300 - ac\n",
      "Epoch 384/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0332 - accuracy: 0.98400s - loss:\n",
      "Epoch 385/400\n",
      "10287/10287 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9806 ETA: 1s - loss: 0.0285 - accura - ETA: 1s - - ETA: 0s - loss: 0.0320 -  - 2s 205us/step - loss: 0.0349 - accuracy: 0.9807\n",
      "Epoch 386/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0328 - accuracy: 0.98421s - loss: 0.0373 - accuracy - ETA: 1s - loss: - ETA: 0s - loss: 0\n",
      "Epoch 387/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0316 - accuracy: 0.98391s - loss: - ETA: 0s - los\n",
      "Epoch 388/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0335 - accuracy: 0.9823\n",
      "Epoch 389/400\n",
      "10287/10287 [==============================] - 2s 203us/step - loss: 0.0324 - accuracy: 0.98300s - loss: 0.0312 -  - ETA: 0s - loss: 0.0321 - accuracy: 0.\n",
      "Epoch 390/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0334 - accuracy: 0.98260s - loss: 0.0343 - ac\n",
      "Epoch 391/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0320 - accuracy: 0.9834 - ETA: 0s - loss: 0.0318 -  - ETA: 0s - loss: 0.0313 - accu\n",
      "Epoch 392/400\n",
      "10287/10287 [==============================] - 2s 210us/step - loss: 0.0348 - accuracy: 0.9824\n",
      "Epoch 393/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0323 - accuracy: 0.9819\n",
      "Epoch 394/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0313 - accuracy: 0.98341s - loss: 0.0304  - ETA: 0s - loss:\n",
      "Epoch 395/400\n",
      "10287/10287 [==============================] - 2s 205us/step - loss: 0.0328 - accuracy: 0.9823\n",
      "Epoch 396/400\n",
      "10287/10287 [==============================] - 2s 204us/step - loss: 0.0321 - accuracy: 0.98231s - loss: - ETA: \n",
      "Epoch 397/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0320 - accuracy: 0.9832\n",
      "Epoch 398/400\n",
      "10287/10287 [==============================] - 2s 202us/step - loss: 0.0351 - accuracy: 0.98210s - loss: 0.0348 - accuracy\n",
      "Epoch 399/400\n",
      "10287/10287 [==============================] - 2s 201us/step - loss: 0.0338 - accuracy: 0.98310s - loss: 0.0\n",
      "Epoch 400/400\n",
      "10287/10287 [==============================] - 2s 206us/step - loss: 0.0319 - accuracy: 0.9829\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.001, decay=1e-8, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#fitting and saving the model \n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=400, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
